{
  "name": "semantic-chunking",
  "version": "2.4.3",
  "description": "Semantically create chunks from large texts. Useful for workflows involving large language models (LLMs).",
  "homepage": "https://www.equilllabs.com/projects/semantic-chunking",
  "repository": {
    "type": "git",
    "url": "https://github.com/jparkerweb/semantic-chunking.git"
  },
  "bugs": {
    "url": "https://github.com/jparkerweb/semantic-chunking/issues",
    "email": "equilllabs@gmail.com"
  },
  "main": "chunkit.js",
  "type": "module",
  "keywords": [
    "semantic",
    "chunking",
    "sentence",
    "similarity",
    "cosine",
    "chunk",
    "rag",
    "splitting",
    "transformers",
    "transformers.js",
    "emmbeddings",
    "onnx",
    "xenova",
    "text-processing",
    "nlp",
    "webui",
    "ml",
    "BERT"
  ],
  "author": "jparkerweb@gmail.com",
  "license": "ISC",
  "scripts": {
    "clean-models": "find ./models -type f ! -name '*.url' -delete",
    "clean-models-win": "powershell -Command \"Get-ChildItem -Path ./models -Recurse | Where-Object { !$_.PSIsContainer -and $_.Extension -ne '.url' } | Remove-Item\"",
    "download-models": "node ./tools/download-models.js",
    "clean": "npx rimraf node_modules package-lock.json && npm install",
    "example-chunkit": "node ./example/example-chunkit.js",
    "example-sentenceit": "node ./example/example-sentenceit.js",
    "example-cramit": "node ./example/example-cramit.js"
  },
  "dependencies": {
    "@huggingface/transformers": "^3.6.1",
    "cli-progress": "^3.12.0",
    "fs": "^0.0.1-security",
    "lru-cache": "^11.1.0",
    "sentence-parse": "^1.3.1"
  }
}
